{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1607a-97f2-4b9d-a18f-ff7e0b216e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seab as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "import cvxpy as cp\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
    "st.title(\"Portfolio Optimization Dashboard\")\n",
    "\n",
    "TICKERS = st.multiselect(\"Select Assets:\", [\n",
    "    \"JPM\", \"GS\", \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"META\",\n",
    "    \"AMZN\", \"HD\", \"KO\", \"XOM\", \"CVX\", \"UNH\", \"PFE\",\n",
    "    \"CAT\", \"UNP\", \"NFLX\", \"DIS\", \"NEE\", \"PLD\"\n",
    "], default=[\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"])\n",
    "\n",
    "START = \"2020-06-01\"\n",
    "END = \"2025-06-01\"\n",
    "\n",
    "@st.cache_data\n",
    "def download_data(tickers):\n",
    "    return yf.download(tickers, start=START, end=END, auto_adjust=True)['Close']\n",
    "\n",
    "if not TICKERS:\n",
    "    st.warning(\"Please select at least one ticker.\")\n",
    "    st.stop()\n",
    "\n",
    "stock_data = download_data(TICKERS)\n",
    "st.write(\"### Adjusted Close Prices Sample\")\n",
    "st.dataframe(stock_data.tail())\n",
    "\n",
    "returns_df = np.log(stock_data / stock_data.shift(1)).dropna()\n",
    "\n",
    "# Risk-return summary\n",
    "risk_return_summary = pd.DataFrame({\n",
    "    'Mean Daily Return': returns_df.mean(),\n",
    "    'Daily Volatility (Std Dev)': returns_df.std()\n",
    "}).sort_values(by='Mean Daily Return', ascending=False)\n",
    "\n",
    "st.write(\"### Risk-Return Summary\")\n",
    "st.dataframe(risk_return_summary)\n",
    "\n",
    "# Correlation heatmaps\n",
    "st.write(\"### Covariance and Correlation Matrices\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.heatmap(returns_df.cov(), cmap='coolwarm', center=0, ax=axes[0])\n",
    "axes[0].set_title('Covariance Matrix')\n",
    "sns.heatmap(returns_df.corr(), annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, ax=axes[1])\n",
    "axes[1].set_title('Correlation Matrix')\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Risk-return scatter plot\n",
    "fig2 = plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Daily Volatility (Std Dev)', y='Mean Daily Return', data=risk_return_summary, s=100)\n",
    "for ticker in risk_return_summary.index:\n",
    "    plt.text(risk_return_summary.loc[ticker, 'Daily Volatility (Std Dev)'] + 0.0001,\n",
    "             risk_return_summary.loc[ticker, 'Mean Daily Return'],\n",
    "             ticker, fontsize=9)\n",
    "plt.xlabel('Daily Volatility (Std Dev)')\n",
    "plt.ylabel('Mean Daily Return')\n",
    "plt.title('Risk-Return Scatter Plot')\n",
    "plt.grid(True)\n",
    "st.pyplot(fig2)\n",
    "\n",
    "# Feature Engineering for Random Forest\n",
    "n_lags = 5\n",
    "X_all = []\n",
    "y_all_dict = {ticker: [] for ticker in TICKERS}\n",
    "\n",
    "for i in range(n_lags, len(returns_df) - 1):\n",
    "    lag_features = returns_df.iloc[i - n_lags:i].values.flatten()\n",
    "    X_all.append(lag_features)\n",
    "    for ticker in TICKERS:\n",
    "        y_all_dict[ticker].append(returns_df.iloc[i + 1][ticker])\n",
    "\n",
    "X = np.array(X_all)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "latest_input = returns_df.iloc[-n_lags:].values.flatten().reshape(1, -1)\n",
    "latest_input_scaled = scaler.transform(latest_input)\n",
    "\n",
    "# Model Training & Prediction\n",
    "predicted_returns = []\n",
    "for ticker in TICKERS:\n",
    "    y = np.array(y_all_dict[ticker])\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_scaled[:len(y)], y)\n",
    "    pred = model.predict(latest_input_scaled)[0]\n",
    "    predicted_returns.append(pred)\n",
    "\n",
    "Pred_returns = np.array(predicted_returns)\n",
    "pred_df = pd.DataFrame({'Ticker': TICKERS, 'Predicted Return': Pred_returns})\n",
    "st.write(\"### Predicted Next-Day Returns\")\n",
    "st.dataframe(pred_df)\n",
    "\n",
    "# Risk-Free Rate\n",
    "rf_data = web.DataReader(\"DGS5\", \"fred\", START, END)\n",
    "avg_rf = rf_data[\"DGS5\"].mean() / 100\n",
    "rf_daily = avg_rf / 252\n",
    "\n",
    "# --- Mean-Variance Optimization ---\n",
    "st.header(\"Mean-Variance Optimization\")\n",
    "n = len(Pred_returns)\n",
    "mu = Pred_returns\n",
    "Sigma = LedoitWolf().fit(returns_df).covariance_\n",
    "\n",
    "max_variance = st.slider(\"Select maximum acceptable portfolio variance:\", min_value=0.00001, max_value=0.001, value=0.0001, step=0.00001)\n",
    "weights_mvo = cp.Variable(n)\n",
    "portfolio_return = mu @ weights_mvo\n",
    "portfolio_variance = cp.quad_form(weights_mvo, Sigma)\n",
    "constraints = [cp.sum(weights_mvo) == 1, portfolio_variance <= max_variance, weights_mvo >= 0]\n",
    "objective = cp.Maximize(portfolio_return)\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve()\n",
    "\n",
    "w_mvo = weights_mvo.value\n",
    "st.write(\"### Optimal Weights (MVO)\")\n",
    "st.bar_chart(pd.Series(w_mvo, index=TICKERS))\n",
    "st.write(f\"Expected Portfolio Return: {portfolio_return.value:.6f}\")\n",
    "st.write(f\"Portfolio Variance: {portfolio_variance.value:.8f}\")\n",
    "\n",
    "# --- Max Sharpe Ratio ---\n",
    "st.header(\"Maximum Sharpe Ratio Optimization\")\n",
    "\n",
    "def neg_sharpe(weights, ret, cov, rf):\n",
    "    port_return = np.dot(weights, ret)\n",
    "    port_vol = np.sqrt(np.dot(weights.T, np.dot(cov, weights)))\n",
    "    return -(port_return - rf) / port_vol\n",
    "\n",
    "bounds = [(0, 0.2)] * n\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "initial = np.repeat(1/n, n)\n",
    "cov_matrix = returns_df[-252:].cov().values\n",
    "\n",
    "res = minimize(neg_sharpe, initial, args=(mu, cov_matrix, rf_daily), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "w_sharpe = res.x\n",
    "\n",
    "st.write(\"### Optimal Weights (Max Sharpe Ratio)\")\n",
    "st.bar_chart(pd.Series(w_sharpe, index=TICKERS))\n",
    "port_return = np.dot(w_sharpe, mu)\n",
    "port_vol = np.sqrt(np.dot(w_sharpe.T, np.dot(cov_matrix, w_sharpe)))\n",
    "sharpe = (port_return - rf_daily) / port_vol\n",
    "st.write(f\"Expected Return: {port_return:.6f}\")\n",
    "st.write(f\"Volatility: {port_vol:.6f}\")\n",
    "st.write(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
    "\n",
    "# --- Equal Weight Portfolio ---\n",
    "st.header(\"Equal Weight Portfolio\")\n",
    "weights_eq = np.repeat(1/n, n)\n",
    "ret_eq = np.dot(weights_eq, mu)\n",
    "vol_eq = np.sqrt(np.dot(weights_eq.T, np.dot(cov_matrix, weights_eq)))\n",
    "sharpe_eq = (ret_eq - rf_daily) / vol_eq\n",
    "st.bar_chart(pd.Series(weights_eq, index=TICKERS))\n",
    "st.write(f\"Expected Return: {ret_eq:.6f}\")\n",
    "st.write(f\"Volatility: {vol_eq:.6f}\")\n",
    "st.write(f\"Sharpe Ratio: {sharpe_eq:.4f}\")\n",
    "\n",
    "# --- Black-Litterman ---\n",
    "st.header(\"Black-Litterman Optimization\")\n",
    "market_caps = []\n",
    "for ticker in TICKERS:\n",
    "    try:\n",
    "        cap = yf.Ticker(ticker).info.get(\"marketCap\", 0)\n",
    "        market_caps.append(cap)\n",
    "    except:\n",
    "        market_caps.append(0)\n",
    "market_weights = pd.Series(market_caps, index=TICKERS)\n",
    "market_weights = market_weights / market_weights.sum()\n",
    "\n",
    "spy = yf.download(\"SPY\", start=START, end=END, auto_adjust=True)['Close']\n",
    "spy_returns = np.log(spy / spy.shift(1)).dropna()\n",
    "delta = ((spy_returns.mean() - rf_daily) / spy_returns.var()).mean()\n",
    "\n",
    "Sigma = LedoitWolf().fit(returns_df).covariance_\n",
    "Sigma_inv = np.linalg.inv(Sigma)\n",
    "Pi = delta * Sigma @ market_weights.values\n",
    "Omega = np.eye(n) * 0.1\n",
    "Omega_inv = np.linalg.inv(Omega)\n",
    "P = np.eye(n)\n",
    "tau = 0.2\n",
    "combined = np.linalg.inv(tau * Sigma_inv + P.T @ Omega_inv @ P)\n",
    "combined_mu = tau * Sigma_inv @ Pi + P.T @ Omega_inv @ mu\n",
    "posterior_mu = combined @ combined_mu\n",
    "\n",
    "w_bl = cp.Variable(n)\n",
    "portfolio_variance = cp.quad_form(w_bl, Sigma)\n",
    "constraints = [cp.sum(w_bl) == 1, w_bl >= 0]\n",
    "objective = cp.Minimize(portfolio_variance)\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve()\n",
    "\n",
    "st.write(\"### Optimal Weights (Black-Litterman)\")\n",
    "st.bar_chart(pd.Series(w_bl.value, index=TICKERS))\n",
    "st.write(f\"Portfolio Variance: {portfolio_variance.value:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f70b54-92b9-4411-b2e7-b096ba690f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
